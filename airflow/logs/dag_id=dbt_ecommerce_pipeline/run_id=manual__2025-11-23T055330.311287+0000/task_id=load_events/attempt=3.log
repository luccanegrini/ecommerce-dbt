[2025-11-23T05:59:01.153+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dbt_ecommerce_pipeline.load_events manual__2025-11-23T05:53:30.311287+00:00 [queued]>
[2025-11-23T05:59:01.157+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dbt_ecommerce_pipeline.load_events manual__2025-11-23T05:53:30.311287+00:00 [queued]>
[2025-11-23T05:59:01.157+0000] {taskinstance.py:2193} INFO - Starting attempt 3 of 4
[2025-11-23T05:59:01.168+0000] {taskinstance.py:2217} INFO - Executing <Task(SnowflakeOperator): load_events> on 2025-11-23 05:53:30.311287+00:00
[2025-11-23T05:59:01.174+0000] {standard_task_runner.py:60} INFO - Started process 826 to run task
[2025-11-23T05:59:01.178+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'dbt_ecommerce_pipeline', 'load_events', 'manual__2025-11-23T05:53:30.311287+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/ecommerce_dbt_pipeline.py', '--cfg-path', '/tmp/tmppvfouvt6']
[2025-11-23T05:59:01.181+0000] {standard_task_runner.py:88} INFO - Job 17: Subtask load_events
[2025-11-23T05:59:01.227+0000] {task_command.py:423} INFO - Running <TaskInstance: dbt_ecommerce_pipeline.load_events manual__2025-11-23T05:53:30.311287+00:00 [running]> on host 7244b0bf02d5
[2025-11-23T05:59:01.292+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='dbt_ecommerce_pipeline' AIRFLOW_CTX_TASK_ID='load_events' AIRFLOW_CTX_EXECUTION_DATE='2025-11-23T05:53:30.311287+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-23T05:53:30.311287+00:00'
[2025-11-23T05:59:01.293+0000] {sql.py:276} INFO - Executing: 
            USE DATABASE ECOMMERCE;
            USE SCHEMA RAW;

            COPY INTO EVENTS (
                EVENT_ID,
                EVENT_TYPE,
                EVENT_TS,
                USER_ID,
                SESSION_ID,
                PAYLOAD,
                INSERTED_AT
            )
            FROM (
                SELECT
                    $1:event_id::string,
                    $1:event_type::string,
                    $1:event_ts::timestamp_ntz,
                    $1:user_id::string,
                    $1:session_id::string,
                    $1:payload,
                    CURRENT_TIMESTAMP()
                FROM @ECOMMERCE_STAGE
            )
            FILE_FORMAT = (TYPE = JSON)
            ON_ERROR = 'CONTINUE';
        
[2025-11-23T05:59:01.299+0000] {base.py:83} INFO - Using connection ID 'snowflake_default' for task execution.
[2025-11-23T05:59:01.468+0000] {base.py:83} INFO - Using connection ID 'snowflake_default' for task execution.
[2025-11-23T05:59:01.469+0000] {connection.py:386} INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.11.8, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-11-23T05:59:01.470+0000] {connection.py:1211} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-11-23T05:59:02.088+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
             ^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 384, in run
    with closing(self.get_conn()) as conn:
                 ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 278, in get_conn
    conn = connector.connect(**conn_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/__init__.py", line 54, in Connect
    return SnowflakeConnection(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/connection.py", line 429, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/connection.py", line 719, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/connection.py", line 1045, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/connection.py", line 1317, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/connection.py", line 1345, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/auth/_auth.py", line 401, in authenticate
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/errors.py", line 348, in hand_to_other_handler
    connection.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.11/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.DatabaseError: 250001 (08001): None: Failed to connect to DB: QMSYQOE-WGA81477.snowflakecomputing.com:443. Incorrect username or password was specified.
[2025-11-23T05:59:02.092+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=dbt_ecommerce_pipeline, task_id=load_events, execution_date=20251123T055330, start_date=20251123T055901, end_date=20251123T055902
[2025-11-23T05:59:02.101+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 17 for task load_events (250001 (08001): None: Failed to connect to DB: QMSYQOE-WGA81477.snowflakecomputing.com:443. Incorrect username or password was specified.; 826)
[2025-11-23T05:59:02.153+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-11-23T05:59:02.163+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py:1201 AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
[2025-11-23T05:59:02.170+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
